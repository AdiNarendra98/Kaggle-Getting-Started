{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "papermill": {
     "duration": 0.011137,
     "end_time": "2022-06-04T07:42:32.632987",
     "exception": false,
     "start_time": "2022-06-04T07:42:32.621850",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:32.658815Z",
     "iopub.status.busy": "2022-06-04T07:42:32.657820Z",
     "iopub.status.idle": "2022-06-04T07:42:32.666524Z",
     "shell.execute_reply": "2022-06-04T07:42:32.666979Z",
     "shell.execute_reply.started": "2022-06-04T07:38:53.208041Z"
    },
    "papermill": {
     "duration": 0.023427,
     "end_time": "2022-06-04T07:42:32.667349",
     "exception": false,
     "start_time": "2022-06-04T07:42:32.643922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data-science-london-scikit-learn/trainLabels.csv\n",
      "/kaggle/input/data-science-london-scikit-learn/train.csv\n",
      "/kaggle/input/data-science-london-scikit-learn/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:32.693512Z",
     "iopub.status.busy": "2022-06-04T07:42:32.692569Z",
     "iopub.status.idle": "2022-06-04T07:42:32.980895Z",
     "shell.execute_reply": "2022-06-04T07:42:32.979939Z",
     "shell.execute_reply.started": "2022-06-04T07:39:11.600629Z"
    },
    "papermill": {
     "duration": 0.30183,
     "end_time": "2022-06-04T07:42:32.981039",
     "exception": false,
     "start_time": "2022-06-04T07:42:32.679209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../input/data-science-london-scikit-learn/train.csv\",header = None)\n",
    "test_data =pd.read_csv(\"../input/data-science-london-scikit-learn/test.csv\",header = None)\n",
    "trainLabel = pd.read_csv(\"../input/data-science-london-scikit-learn/trainLabels.csv\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:33.010093Z",
     "iopub.status.busy": "2022-06-04T07:42:33.009040Z",
     "iopub.status.idle": "2022-06-04T07:42:33.043291Z",
     "shell.execute_reply": "2022-06-04T07:42:33.043785Z",
     "shell.execute_reply.started": "2022-06-04T07:39:14.292121Z"
    },
    "papermill": {
     "duration": 0.052345,
     "end_time": "2022-06-04T07:42:33.043951",
     "exception": false,
     "start_time": "2022-06-04T07:42:32.991606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299403</td>\n",
       "      <td>-1.226624</td>\n",
       "      <td>1.498425</td>\n",
       "      <td>-1.176150</td>\n",
       "      <td>5.289853</td>\n",
       "      <td>0.208297</td>\n",
       "      <td>2.404498</td>\n",
       "      <td>1.594506</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850465</td>\n",
       "      <td>-0.622990</td>\n",
       "      <td>-1.833057</td>\n",
       "      <td>0.293024</td>\n",
       "      <td>3.552681</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>3.305972</td>\n",
       "      <td>-2.715559</td>\n",
       "      <td>-2.682409</td>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819750</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604501</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513906</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n",
       "1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n",
       "2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n",
       "3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n",
       "4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n",
       "\n",
       "         7         8         9   ...        30        31        32        33  \\\n",
       "0  1.594506 -0.051608  0.663234  ... -0.850465 -0.622990 -1.833057  0.293024   \n",
       "1  2.619246 -0.765884 -0.093780  ... -0.819750  0.012037  2.038836  0.468579   \n",
       "2 -4.219054 -1.184919 -1.240310  ... -0.604501  0.750054 -3.360521  0.856988   \n",
       "3  4.499666  1.038741 -1.092716  ...  1.022959  1.275598 -3.480110 -1.065252   \n",
       "4 -4.290282 -1.761308  0.807652  ...  0.513906 -1.803473  0.518579 -0.205029   \n",
       "\n",
       "         34        35        36        37        38        39  \n",
       "0  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n",
       "1 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n",
       "2 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n",
       "3  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n",
       "4 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:33.069072Z",
     "iopub.status.busy": "2022-06-04T07:42:33.068162Z",
     "iopub.status.idle": "2022-06-04T07:42:33.073708Z",
     "shell.execute_reply": "2022-06-04T07:42:33.074220Z",
     "shell.execute_reply.started": "2022-06-04T07:39:15.513132Z"
    },
    "papermill": {
     "duration": 0.019628,
     "end_time": "2022-06-04T07:42:33.074388",
     "exception": false,
     "start_time": "2022-06-04T07:42:33.054760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 40), (9000, 40), (1000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape , test_data.shape , trainLabel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01085,
     "end_time": "2022-06-04T07:42:33.096288",
     "exception": false,
     "start_time": "2022-06-04T07:42:33.085438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ****pre processing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:33.121913Z",
     "iopub.status.busy": "2022-06-04T07:42:33.120998Z",
     "iopub.status.idle": "2022-06-04T07:42:34.088647Z",
     "shell.execute_reply": "2022-06-04T07:42:34.087974Z",
     "shell.execute_reply.started": "2022-06-04T07:39:17.639032Z"
    },
    "papermill": {
     "duration": 0.981536,
     "end_time": "2022-06-04T07:42:34.088790",
     "exception": false,
     "start_time": "2022-06-04T07:42:33.107254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test , y_train ,y_test = train_test_split(train_data , trainLabel,test_size=.33 ,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011896,
     "end_time": "2022-06-04T07:42:34.113422",
     "exception": false,
     "start_time": "2022-06-04T07:42:34.101526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:34.147337Z",
     "iopub.status.busy": "2022-06-04T07:42:34.146577Z",
     "iopub.status.idle": "2022-06-04T07:42:35.706945Z",
     "shell.execute_reply": "2022-06-04T07:42:35.707544Z",
     "shell.execute_reply.started": "2022-06-04T07:39:30.809232Z"
    },
    "papermill": {
     "duration": 1.583069,
     "end_time": "2022-06-04T07:42:35.707735",
     "exception": false,
     "start_time": "2022-06-04T07:42:34.124666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bauyes 0.8212121212121212\n",
      "confusion matrix [[127  29]\n",
      " [ 30 144]]\n",
      "KNN 0.8878787878787879\n",
      "confusion matrix [[139  19]\n",
      " [ 18 154]]\n",
      "ÙŒRadom Forest 0.8454545454545455\n",
      "confusion matrix [[130  24]\n",
      " [ 27 149]]\n",
      " Logistic Rg 0.8303030303030303\n",
      "confusion matrix [[127  26]\n",
      " [ 30 147]]\n",
      " SVC 0.9\n",
      "confusion matrix [[141  17]\n",
      " [ 16 156]]\n",
      " Decision tree 0.7606060606060606\n",
      "confusion matrix [[114  36]\n",
      " [ 43 137]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:42:35] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " XGBoost 0.8666666666666667\n",
      "confusion matrix [[134  21]\n",
      " [ 23 152]]\n"
     ]
    }
   ],
   "source": [
    "#naive_bayes\n",
    "from sklearn.metrics import accuracy_score ,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train,y_train.values.ravel())\n",
    "predictor = classifier.predict(x_test)\n",
    "print(\"Naive Bauyes\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "##knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(x_train , y_train.values.ravel())\n",
    "predictor=  classifier.predict(x_test)\n",
    "print(\"KNN\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "## Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_model = RandomForestClassifier(n_estimators = 150 , random_state =42)\n",
    "rfc_model.fit(x_train ,y_train.values.ravel())\n",
    "predictor = rfc_model.predict(x_test)\n",
    "\n",
    "print(\"ÙŒRadom Forest\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "##logist regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver=\"sag\")\n",
    "classifier.fit(x_train , y_train.values.ravel())\n",
    "predictor = classifier.predict(x_test)\n",
    "\n",
    "print(\" Logistic Rg\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "\n",
    "## SVC\n",
    "from sklearn.svm import SVC\n",
    "predictor = SVC(gamma=\"auto\").fit(x_train , y_train.values.ravel()).predict(x_test)\n",
    "print(\" SVC\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "####Decision tree \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "predictor  = DecisionTreeClassifier().fit(x_train,y_train.values.ravel()).predict(x_test)\n",
    "\n",
    "print(\" Decision tree\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "predictor  = XGBClassifier().fit(x_train,y_train.values.ravel()).predict(x_test)\n",
    "\n",
    "print(\" XGBoost\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:35.736089Z",
     "iopub.status.busy": "2022-06-04T07:42:35.735467Z",
     "iopub.status.idle": "2022-06-04T07:42:35.744900Z",
     "shell.execute_reply": "2022-06-04T07:42:35.745357Z",
     "shell.execute_reply.started": "2022-06-04T07:39:51.844142Z"
    },
    "papermill": {
     "duration": 0.025248,
     "end_time": "2022-06-04T07:42:35.745540",
     "exception": false,
     "start_time": "2022-06-04T07:42:35.720292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler ,Normalizer\n",
    "scaler = Normalizer()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:35.774724Z",
     "iopub.status.busy": "2022-06-04T07:42:35.774133Z",
     "iopub.status.idle": "2022-06-04T07:42:36.747736Z",
     "shell.execute_reply": "2022-06-04T07:42:36.748285Z",
     "shell.execute_reply.started": "2022-06-04T07:40:30.696244Z"
    },
    "papermill": {
     "duration": 0.989539,
     "end_time": "2022-06-04T07:42:36.748484",
     "exception": false,
     "start_time": "2022-06-04T07:42:35.758945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bauyes 0.8090909090909091\n",
      "confusion matrix [[126  32]\n",
      " [ 31 141]]\n",
      "KNN 0.8787878787878788\n",
      "confusion matrix [[134  17]\n",
      " [ 23 156]]\n",
      "ÙŒRadom Forest 0.8666666666666667\n",
      "confusion matrix [[134  21]\n",
      " [ 23 152]]\n",
      " Logistic Rg 0.8242424242424242\n",
      "confusion matrix [[129  30]\n",
      " [ 28 143]]\n",
      " SVC 0.8151515151515152\n",
      "confusion matrix [[129  33]\n",
      " [ 28 140]]\n",
      " Decision tree 0.7909090909090909\n",
      "confusion matrix [[121  33]\n",
      " [ 36 140]]\n",
      "[07:42:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " XGBoost 0.8757575757575757\n",
      "confusion matrix [[133  17]\n",
      " [ 24 156]]\n"
     ]
    }
   ],
   "source": [
    "#naive_bayes\n",
    "from sklearn.metrics import accuracy_score ,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train,y_train.values.ravel())\n",
    "predictor = classifier.predict(x_test)\n",
    "print(\"Naive Bauyes\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "##knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(x_train , y_train.values.ravel())\n",
    "predictor=  classifier.predict(x_test)\n",
    "print(\"KNN\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "## Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_model = RandomForestClassifier(n_estimators = 150 , random_state =42)\n",
    "rfc_model.fit(x_train ,y_train.values.ravel())\n",
    "predictor = rfc_model.predict(x_test)\n",
    "\n",
    "print(\"ÙŒRadom Forest\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "##logist regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver=\"sag\")\n",
    "classifier.fit(x_train , y_train.values.ravel())\n",
    "predictor = classifier.predict(x_test)\n",
    "\n",
    "print(\" Logistic Rg\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "\n",
    "## SVC\n",
    "from sklearn.svm import SVC\n",
    "predictor = SVC(gamma=\"auto\").fit(x_train , y_train.values.ravel()).predict(x_test)\n",
    "print(\" SVC\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "####Decision tree \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "predictor  = DecisionTreeClassifier().fit(x_train,y_train.values.ravel()).predict(x_test)\n",
    "\n",
    "print(\" Decision tree\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "predictor  = XGBClassifier().fit(x_train,y_train.values.ravel()).predict(x_test)\n",
    "\n",
    "print(\" XGBoost\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:36.782394Z",
     "iopub.status.busy": "2022-06-04T07:42:36.781319Z",
     "iopub.status.idle": "2022-06-04T07:42:36.899369Z",
     "shell.execute_reply": "2022-06-04T07:42:36.894707Z",
     "shell.execute_reply.started": "2022-06-04T07:40:34.373489Z"
    },
    "papermill": {
     "duration": 0.137447,
     "end_time": "2022-06-04T07:42:36.899640",
     "exception": false,
     "start_time": "2022-06-04T07:42:36.762193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "pca = PCA(n_components=12)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:36.988433Z",
     "iopub.status.busy": "2022-06-04T07:42:36.974987Z",
     "iopub.status.idle": "2022-06-04T07:42:37.903828Z",
     "shell.execute_reply": "2022-06-04T07:42:37.904332Z",
     "shell.execute_reply.started": "2022-06-04T07:40:43.375938Z"
    },
    "papermill": {
     "duration": 0.962704,
     "end_time": "2022-06-04T07:42:37.904508",
     "exception": false,
     "start_time": "2022-06-04T07:42:36.941804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bauyes 0.8242424242424242\n",
      "confusion matrix [[121  22]\n",
      " [ 36 151]]\n",
      "KNN 0.9\n",
      "confusion matrix [[141  17]\n",
      " [ 16 156]]\n",
      "ÙŒRadom Forest 0.8909090909090909\n",
      "confusion matrix [[139  18]\n",
      " [ 18 155]]\n",
      " Logistic Rg 0.8212121212121212\n",
      "confusion matrix [[125  27]\n",
      " [ 32 146]]\n",
      " SVC 0.8242424242424242\n",
      "confusion matrix [[127  28]\n",
      " [ 30 145]]\n",
      " Decision tree 0.793939393939394\n",
      "confusion matrix [[123  34]\n",
      " [ 34 139]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:42:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " XGBoost 0.896969696969697\n",
      "confusion matrix [[139  16]\n",
      " [ 18 157]]\n"
     ]
    }
   ],
   "source": [
    "#naive_bayes\n",
    "from sklearn.metrics import accuracy_score ,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train,y_train.values.ravel())\n",
    "predictor = classifier.predict(x_test)\n",
    "print(\"Naive Bauyes\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "##knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(x_train , y_train.values.ravel())\n",
    "predictor=  classifier.predict(x_test)\n",
    "print(\"KNN\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "## Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_model = RandomForestClassifier(n_estimators = 151 , random_state =42)\n",
    "rfc_model.fit(x_train ,y_train.values.ravel())\n",
    "predictor = rfc_model.predict(x_test)\n",
    "\n",
    "print(\"ÙŒRadom Forest\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "##logist regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver=\"sag\")\n",
    "classifier.fit(x_train , y_train.values.ravel())\n",
    "predictor = classifier.predict(x_test)\n",
    "\n",
    "print(\" Logistic Rg\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "\n",
    "## SVC\n",
    "from sklearn.svm import SVC\n",
    "predictor = SVC(gamma=\"auto\").fit(x_train , y_train.values.ravel()).predict(x_test)\n",
    "print(\" SVC\" , accuracy_score(y_test,predictor))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "####Decision tree \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "predictor  = DecisionTreeClassifier().fit(x_train,y_train.values.ravel()).predict(x_test)\n",
    "\n",
    "print(\" Decision tree\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "predictor  = XGBClassifier().fit(x_train,y_train.values.ravel()).predict(x_test)\n",
    "\n",
    "print(\" XGBoost\" , accuracy_score(predictor,y_test))\n",
    "print(\"confusion matrix\" , confusion_matrix(predictor,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014867,
     "end_time": "2022-06-04T07:42:37.934474",
     "exception": false,
     "start_time": "2022-06-04T07:42:37.919607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "the best are knn , random forest and xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:42:37.967032Z",
     "iopub.status.busy": "2022-06-04T07:42:37.966231Z",
     "iopub.status.idle": "2022-06-04T07:43:22.557375Z",
     "shell.execute_reply": "2022-06-04T07:43:22.556166Z",
     "shell.execute_reply.started": "2022-06-04T07:40:48.282917Z"
    },
    "papermill": {
     "duration": 44.608811,
     "end_time": "2022-06-04T07:43:22.557546",
     "exception": false,
     "start_time": "2022-06-04T07:42:37.948735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_all shape : (10000, 40)\n"
     ]
    }
   ],
   "source": [
    "# USING THE GAUSSIAN MIXTURE MODEL \n",
    "from sklearn.mixture import GaussianMixture\n",
    "x_all = np.r_[train_data,test_data]\n",
    "print('x_all shape :',x_all.shape)\n",
    "lowest_bic = np.infty\n",
    "\n",
    "bic = []\n",
    "n_components_range = range(1, 7)\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        gmm = GaussianMixture(n_components=n_components,covariance_type=cv_type)\n",
    "        gmm.fit(x_all)\n",
    "        bic.append(gmm.aic(x_all))\n",
    "        \n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm\n",
    "            \n",
    "            \n",
    "best_gmm.fit(x_all)\n",
    "gmm_train = best_gmm.predict_proba(train_data)\n",
    "gmm_test = best_gmm.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:43:22.600562Z",
     "iopub.status.busy": "2022-06-04T07:43:22.599961Z",
     "iopub.status.idle": "2022-06-04T07:43:47.118493Z",
     "shell.execute_reply": "2022-06-04T07:43:47.119579Z",
     "shell.execute_reply.started": "2022-06-04T07:41:34.709587Z"
    },
    "papermill": {
     "duration": 24.54711,
     "end_time": "2022-06-04T07:43:47.119797",
     "exception": false,
     "start_time": "2022-06-04T07:43:22.572687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Score 0.9960000000000001\n",
      "Random Forest Best Parmas {'max_depth': 3, 'n_estimators': 10}\n",
      "Random Forest Accuracy 0.9960000000000001\n",
      "KNN Best Score 0.9960000000000001\n",
      "KNN Best Params {'n_neighbors': 3}\n",
      "KNN Accuracy 0.9960000000000001\n",
      "SVM Best Score 0.9960000000000001\n",
      "SVM Best Params {'C': 1, 'kernel': 'linear'}\n",
      "SVM Accuracy 0.9960000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Random Forest Classifier\n",
    "rfc = RandomForestClassifier(random_state=99)\n",
    "\n",
    "#USING GRID SEARCH\n",
    "n_estimators = [10, 50, 100, 200,400]\n",
    "max_depth = [3, 10, 20, 40]\n",
    "param_grid = dict(n_estimators=n_estimators,max_depth=max_depth)\n",
    "\n",
    "grid_search_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv = 10,scoring='accuracy',n_jobs=-1).fit(gmm_train, trainLabel.values.ravel())\n",
    "rfc_best = grid_search_rfc.best_estimator_\n",
    "print('Random Forest Best Score',grid_search_rfc.best_score_)\n",
    "print('Random Forest Best Parmas',grid_search_rfc.best_params_)\n",
    "print('Random Forest Accuracy',cross_val_score(rfc_best,gmm_train, trainLabel.values.ravel(), cv=10).mean())\n",
    "\n",
    "#KNN \n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#USING GRID SEARCH\n",
    "n_neighbors=[3,5,6,7,8,9,10]\n",
    "param_grid = dict(n_neighbors=n_neighbors)\n",
    "\n",
    "grid_search_knn = GridSearchCV(estimator=knn, param_grid=param_grid, cv = 10, n_jobs=-1,scoring='accuracy').fit(gmm_train,trainLabel.values.ravel())\n",
    "knn_best = grid_search_knn.best_estimator_\n",
    "print('KNN Best Score', grid_search_knn.best_score_)\n",
    "print('KNN Best Params',grid_search_knn.best_params_)\n",
    "print('KNN Accuracy',cross_val_score(knn_best,gmm_train, trainLabel.values.ravel(), cv=10).mean())\n",
    "\n",
    "#SVM\n",
    "svc = SVC()\n",
    "\n",
    "#USING GRID SEARCH\n",
    "parameters = [{'kernel':['linear'],'C':[1,10,100]},\n",
    "              {'kernel':['rbf'],'C':[1,10,100],'gamma':[0.05,0.0001,0.01,0.001]}]\n",
    "grid_search_svm = GridSearchCV(estimator=svc, param_grid=parameters, cv = 10, n_jobs=-1,scoring='accuracy').fit(gmm_train, trainLabel.values.ravel())\n",
    "svm_best = grid_search_svm.best_estimator_\n",
    "print('SVM Best Score',grid_search_svm.best_score_)\n",
    "print('SVM Best Params',grid_search_svm.best_params_)\n",
    "print('SVM Accuracy',cross_val_score(svm_best,gmm_train, trainLabel.values.ravel(), cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T07:43:47.157821Z",
     "iopub.status.busy": "2022-06-04T07:43:47.156866Z",
     "iopub.status.idle": "2022-06-04T07:43:47.202511Z",
     "shell.execute_reply": "2022-06-04T07:43:47.201848Z",
     "shell.execute_reply.started": "2022-06-04T07:42:04.826849Z"
    },
    "papermill": {
     "duration": 0.067506,
     "end_time": "2022-06-04T07:43:47.202657",
     "exception": false,
     "start_time": "2022-06-04T07:43:47.135151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfc_best.fit(gmm_train,trainLabel.values.ravel())\n",
    "pred  = rfc_best.predict(gmm_test)\n",
    "rfc_best_pred = pd.DataFrame(pred)\n",
    "\n",
    "rfc_best_pred.index += 1\n",
    "\n",
    "rfc_best_pred.columns = ['Solution']\n",
    "rfc_best_pred['Id'] = np.arange(1,rfc_best_pred.shape[0]+1)\n",
    "rfc_best_pred = rfc_best_pred[['Id', 'Solution']]\n",
    "\n",
    "\n",
    "rfc_best_pred.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.015309,
     "end_time": "2022-06-04T07:43:47.233549",
     "exception": false,
     "start_time": "2022-06-04T07:43:47.218240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 80.654218,
   "end_time": "2022-06-04T07:43:48.059584",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-04T07:42:27.405366",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
